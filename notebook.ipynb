{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAr8y3LSAYOB"
      },
      "outputs": [],
      "source": [
        "# !cp -rf ./drive/MyDrive/CS747/project/archive.zip .\n",
        "# !cp -rf ./drive/MyDrive/CS747/project/checkpoint.pt ./checkpoints/checkpoint.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13z2muWnEx1P"
      },
      "outputs": [],
      "source": [
        "# !unzip archive.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09YEWHaFIc--"
      },
      "outputs": [],
      "source": [
        "# !rm -rf Data/hd_specs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDOjGd5aE6VK"
      },
      "outputs": [],
      "source": [
        "# !cp Data/genres_original/jazz/jazz.00053.wav Data/genres_original/jazz/jazz.00054.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vznTmMdlFRlr",
        "outputId": "d18b75ed-8c6b-4eb4-a555-6e27bece5717"
      },
      "outputs": [],
      "source": [
        "from model.RobNet import *\n",
        "from train import train\n",
        "from torchvision.models import vgg16\n",
        "import torch.nn as nn\n",
        "\n",
        "model = RobNetMel()\n",
        "\n",
        "# model = vgg16(weights='DEFAULT')\n",
        "# model.classifier[6] = nn.Linear(4096, 10)\n",
        "# model.classifier.add_module('softmax', nn.Softmax(dim=1))\n",
        "# print(model)\n",
        "\n",
        "train(model, 200, 32, 0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lt6YQXPLjK8M",
        "outputId": "adc74aa1-250e-41b1-8aec-961779860b9c"
      },
      "outputs": [],
      "source": [
        "from model.RobNet import RobNetMel\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "\n",
        "model = RobNetMel().to(device)\n",
        "model.load_state_dict(torch.load('checkpoints/checkpoint.pt')[\"model_state_dict\"])\n",
        "model.eval()\n",
        "\n",
        "print(model)\n",
        "\n",
        "return_nodes = {\n",
        "    \"block4\": \"block4\"\n",
        "}\n",
        "model2 = create_feature_extractor(model, return_nodes=return_nodes)\n",
        "\n",
        "blues = torch.load('Data/hd_specs/blues.00000.wav.pt')\n",
        "classical = torch.load('Data/hd_specs/classical.00000.wav.pt')\n",
        "country = torch.load('Data/hd_specs/country.00000.wav.pt')\n",
        "disco = torch.load('Data/hd_specs/disco.00000.wav.pt')\n",
        "hiphop = torch.load('Data/hd_specs/hiphop.00000.wav.pt')\n",
        "jazz = torch.load('Data/hd_specs/jazz.00000.wav.pt')\n",
        "metal = torch.load('Data/hd_specs/metal.00000.wav.pt')\n",
        "pop = torch.load('Data/hd_specs/pop.00000.wav.pt')\n",
        "reggae = torch.load('Data/hd_specs/reggae.00000.wav.pt')\n",
        "rock = torch.load('Data/hd_specs/rock.00000.wav.pt')\n",
        "\n",
        "class_dict = {\n",
        "  'blues': 0,\n",
        "  'classical': 1,\n",
        "  'country': 2,\n",
        "  'disco': 3,\n",
        "  'hiphop': 4,\n",
        "  'jazz': 5,\n",
        "  'metal': 6,\n",
        "  'pop': 7,\n",
        "  'reggae': 8,\n",
        "  'rock': 9,\n",
        "}\n",
        "\n",
        "\n",
        "for i, tensor in enumerate([blues, classical, country, disco, hiphop, jazz, metal, pop, reggae, rock]):\n",
        "  tensor = tensor.to(device)\n",
        "  # probs = torch.argmax(model(tensor[None, :128, :320]))\n",
        "  # print(f'Expected {i}, predicted {torch.argmax(probs, dim=0).item()}')\n",
        "  input = tensor.detach()[0,:,:].cpu()\n",
        "  features = model2(tensor[None, :128, :320])\n",
        "  print(features[\"block4\"].size())\n",
        "  print(input.shape)\n",
        "  print('\\n\\nTensor', i)\n",
        "  plt.imshow(input, origin='lower')\n",
        "  plt.show()\n",
        "  for j in range(features[\"block4\"].size()[1]):\n",
        "    plt.imshow(features[\"block4\"].detach().cpu().numpy()[0, j,:,:], origin=\"lower\")\n",
        "    plt.show()\n",
        "  # print(f'Expected {i}, predicted {torch.argmax(probs, dim=0).item()}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6 (default, Jan  8 2020, 13:42:34) \n[Clang 4.0.1 (tags/RELEASE_401/final)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "5f1b116c61407119096fb2ef255e87e9c0661cc8842a68e54029641db2bf4188"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
